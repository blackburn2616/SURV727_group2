---
title: "Assignment 2"
subtitle: "Due at 11:59pm on October 3."
subtitle: "Nicole Blackburn and Jianing Zou"
format: pdf
editor: visual
---

You may work in pairs or individually for this assignment. Make sure you join a group in Canvas if you are working in pairs. Turn in this assignment as an HTML or PDF file to ELMS. Make sure to include the R Markdown or Quarto file that was used to generate it.

```{r}
#| message: FALSE
library(tidyverse)
library(epidatr)
library(censusapi)
```

In this assignment, you will pull from APIs to get data from various data sources and use your data wrangling skills to use them all together. You should turn in a report in PDF or HTML format that addresses all of the questions in this assignment, and describes the data that you pulled and analyzed. You do not need to include full introduction and conclusion sections like a full report, but you should make sure to answer the questions in paragraph form, and include all relevant tables and graphics.

Whenever possible, use piping and `dplyr`. Avoid hard-coding any numbers within the report as much as possible.

## Pulling from APIs

Our first data source is the Delphi COVIDcast data. You can access this using the Epidata API built by Carnegie Mellon University's Delphi Research group. Documentation for this API can be found here: <https://cmu-delphi.github.io/delphi-epidata/>. Here, we find the smoothed estimate of the proportion of people experiencing Covid-like symptoms by county from April 6, 2020 to April 14, 2020.

```{r}
#| eval: FALSE

covid_april <- pub_covidcast('fb-survey', 
                       'smoothed_wcli', 
                       'county', 
                       'day', 
                       time_values = c(20200406:20200414))
head(covid_april)
```

For more information about the data, see: <https://cmu-delphi.github.io/delphi-epidata/api/covidcast_signals.html>

Answer the following questions:

-   Change the data from long to wide format by including the estimate of Covid-like symptoms for each day as a column. There should be a column for `geo_value` as well as a column for each of the days in the dataset.

```{r}
#Nicole
#long to wide format

covid_april |> 
  pivot_wider(
    id_cols = geo_value,
    names_from = time_value,
    values_from = value
  )
```

-   Find the mean, median, and variance of the estimate on each of the days from April 6, 2020 to April 14, 2020. (Note that this is not the appropriate way of finding the overall measures in reality because we aren't using weights)

```{r}
#Nicole
#mean, median, and variance by date

covid_april |> 
  group_by(time_value) |> 
  summarize(
    mean = mean(value),
    median = median(value),
    variance = var(value)
  )
```

-   Which counties had the highest report Covid-like symptoms on each of the days within this range?

```{r}
#Nicole
#counties

covid_april |> 
  select(time_value, geo_value, value) |> 
  group_by(time_value) |> 
  arrange(desc(value)) |> 
  slice_head(n = 1)
```

-   On April 6, 2020, county 36005 (Bronx County, NY) had the highest report of Covid-like symptoms. From April 7, 2020 - April 13, 2020, county 36087 (Rockland County, NY) has the highest report of Covid-like symptoms. On April 14, 2020, county 36079 (Putnam County, NY) had the highest report of Covid-like symptoms.

Using the API, get the actual COVID cases from the JHU Cases and Deaths (using the link above, `confirmed_7dav_incidence_prop`) from May 6, 2020 to May 14, 2020. This is the number of confirmed COVID cases per 100,000 people. Find the correlation between reported COVID-like symptoms and actual COVID cases per 100,000 people within each county a month later. Is there a relationship?

```{r}
#Jianing
#actual covid cases from JHU cases and deaths
covid_may <- pub_covidcast('jhu-csse', 
                       'confirmed_7dav_incidence_prop', 
                       'county', 
                       'day', 
                       time_values = c(20200506:20200514))
#head(covid_may)

library(lubridate)

covid_both <- 
  covid_april |> 
  mutate(day_apr = day(time_value)) |> 
  inner_join(
    covid_may |> 
      mutate(day_may = day(time_value)), 
    join_by(geo_value, day_apr == day_may))
```

*Hint: Join by location and date*

```{r}
#Jianing
#find correlation between april symptoms and may cases
#join by county and date in order to get corrrelation
```

## Covidcast API Data + ACS

Now lets add another data set. The `censusapi` package provides a nice R interface for communicating with this API. However, before running queries we need an access key. This (easy) process can be completed here:

<https://api.census.gov/data/key_signup.html>

Once you have an access key, save it as a text file, then read this key in the `cs_key` object. We will use this object in all following API queries. Note that I called my text file `census-key.txt` â€“ yours might be different!

```{r}
#Nicole
cs_key <- read_file("C:/Users/npbvb/OneDrive - University of Maryland/R_Projects/727/APIs/census-key")
```

```{r}
#Jianing
#cs_key <- read_file("census-key")
```

You can navigate through the documentation for all Census Data APIs here: <https://www.census.gov/data/developers/data-sets.html> Documentation for the 5-year ACS API can be found here: <https://www.census.gov/data/developers/data-sets/acs-5year.html>.

In the following, we request basic socio-demographic information (population, median age, median household income, income per capita) for counties in the US. The information about the variables used here can be found here: <https://api.census.gov/data/2022/acs/acs5/variables.html>.

```{r}
acs <- getCensus(name = "acs/acs5",
                    vintage = 2020, 
                    vars = c("NAME", 
                             "B01001_001E", 
                             "B06002_001E", 
                             "B19013_001E", 
                             "B19301_001E"), 
                    region = "county",
                    key = cs_key)
head(acs)
```

Now, it might be useful to rename the socio-demographic variables (`B01001_001E` etc.) in our data set and assign more meaningful names.

```{r}
acs <-
  acs %>%
  rename(pop = B01001_001E, 
         age = B06002_001E, 
         hh_income = B19013_001E, 
         income = B19301_001E)
```

It seems like we could try to use this location information listed above to merge this data set with the COVID data. However, we first have to clean the geography data to match the two datasets. The COVID data has a five digit geography code, with the first two digits representing the state and the last three representing the county within that state. The ACS data has this separated out. Add a new variable `location` to the ACS data that has the geography value in the same format as the COVID data.

```{r}
#Nicole
#add location variable to ACS data

acs <- acs |> 
        mutate(
        location = paste0(state, county),
         .after = county)
```

Answer the following questions with the COVID data and ACS data.

-   First, check how many counties aren't matched. Then, create a new data set by joining the two datasets. Keep only counties that appear in both data sets.

```{r}
#Nicole

#From the Delphi Epidata API on Geographic coding - "Megacounty estimates are reported with a FIPS code ending with 000, which is never a FIPS code for a real county"

#counties in covid_april that aren't in acs
covid_both |> 
  distinct(location = geo_value) |> 
  anti_join(acs) 
#[51] counties ending in 000; multiple observations per county

#counties in acs that aren't in covid_april
acs |> 
  distinct(geo_value = location) |> 
  anti_join(covid_both) 
#[1,810] counties 

acs |> 
  count(location) |> 
  filter(n > 1)

############################## update with COVID joined dataset

covid_both1 <-  covid_both |> 
  select(geo_value, time_value.x, time_value.y, value.x, value.y)

by <- join_by(location == geo_value)
combined <- inner_join(acs, covid_both1, by) 
head(combined)
```

-   Compute the mean of the proportion of people with covid-like illness symptoms on April 6, 2020 for counties that have an above average median household income and for those that have an below average median household income. When building your pipe, start with creating the grouping variable and then proceed with the remaining tasks. What conclusions might you draw from this?

```{r}
#Nicole
#compute mean of symptoms on April 6 for counties by above/below average hh income

#April 6
combined |> 
  group_by(above_avg_hh = hh_income > mean(combined$hh_income)) |> 
  filter(time_value.x == as.Date("2020-04-06")) |> 
  summarize( 
    mean_prop = mean(value.x)
  )

#By date
combined |> 
  group_by(time_value.x, 
           above_avg_hh = hh_income > mean(hh_income)) |> 
  summarize(
    mean_prop = mean(value.x)) |> 
      pivot_wider(
        names_from = above_avg_hh,
        values_from = mean_prop)
```

On April 6th, 2020, counties with above average median household income had a higher proportion of recorded COVID symptoms than counties with below average median household income. Conclusions: maybe individuals with lower income aren't testing on april 6, 2020; New York had the most covid cases in the beginning of the pandemic and maybe has higher household income compared to all counties. From April 7 - April 14, we see the opposite - counties with below average median household income had a higher proportion of COVID symptoms than counties with above average hh_income. This makes sense considering the relationship between essential workers or lower income jobs and covid contraction vs. "white collar" or higher income jobs that were able to give employees the option to work from home, reducing covid contraction.

-   Is there a relationship between the median household income and the proportion of people reporting Covid-like illness symptoms? Describe the relationship and use a scatterplot.

```{r}
#Nicole
#relationship between hh_income and value.x

ggplot(data = combined, aes(x = hh_income, y = value.x)) +
  geom_point(alpha = 0.2)

ggplot(data = combined, aes(x = hh_income, y = value.x)) +
  geom_point(alpha = 0.2) +
  facet_wrap(~time_value.x)

combined |> 
  filter(hh_income > 120000) |> 
  group_by(time_value.x) |> 
  summarize(range(value.x))
combined |> 
  filter(hh_income < 120000) |> 
  group_by(time_value.x) |> 
  summarize(range(value.x))
```

-   counties with very high hh_income do not have proportions close to 0.

## Using Other Census Data

Suppose we wanted to use the 2020 1-year ACS instead of the 5-year ACS. Why would we be unable to do this?

*Hint: Read the documentation for the 1-year ACS*

```{r}
#Jianing, you might not need to write code for this, just wanted to add a chunk here so it was easy to see this section
```

Instead, repeat the steps above to merge the Delphi COVIDcast data to the 1-year ACS from\
2021 (rather than the 5-year ACS). Do the same analysis as above.

```{r}
#Jianing
#Waiting on Brian
```
